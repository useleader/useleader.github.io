<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 6.3.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">
  <link rel="stylesheet" href="/lib/pace/pace-theme-minimal.min.css">
  <script src="/lib/pace/pace.min.js"></script>

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"www.warmfire.com","root":"/","scheme":"Muse","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":false,"show_result":false,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":true,"trigger":"manual","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},"path":"search.xml"};
  </script>

  <meta name="description" content="0x00 前言 GANLM论文翻译">
<meta property="og:type" content="article">
<meta property="og:title" content="GANLM: Encoder-Decoder Pre-training with an Auxiliary Discriminator">
<meta property="og:url" content="http://www.warmfire.com/2023/11/27/%E7%A7%91%E7%A0%94%E7%AB%9E%E8%B5%9B/GANLM-Encoder-Decoder-Pre-training-with-an-Auxiliary-Discriminator/index.html">
<meta property="og:site_name" content="WarmFire">
<meta property="og:description" content="0x00 前言 GANLM论文翻译">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="http://warmfire-store.oss-cn-beijing.aliyuncs.com//img/image-20231127231837770.png">
<meta property="og:image" content="http://warmfire-store.oss-cn-beijing.aliyuncs.com//img/image-20231128100203852.png">
<meta property="og:image" content="http://warmfire-store.oss-cn-beijing.aliyuncs.com//img/image-20231128104227297.png">
<meta property="og:image" content="http://warmfire-store.oss-cn-beijing.aliyuncs.com//img/image-20231128104355560.png">
<meta property="og:image" content="http://warmfire-store.oss-cn-beijing.aliyuncs.com//img/image-20231128104426541.png">
<meta property="og:image" content="http://warmfire-store.oss-cn-beijing.aliyuncs.com//img/image-20231128105705309.png">
<meta property="og:image" content="http://warmfire-store.oss-cn-beijing.aliyuncs.com//img/image-20231128105718279.png">
<meta property="article:published_time" content="2023-11-27T14:58:34.000Z">
<meta property="article:modified_time" content="2024-01-10T07:10:18.902Z">
<meta property="article:author" content="Yan Zhimin">
<meta property="article:tag" content="科研竞赛">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://warmfire-store.oss-cn-beijing.aliyuncs.com//img/image-20231127231837770.png">

<link rel="canonical" href="http://www.warmfire.com/2023/11/27/%E7%A7%91%E7%A0%94%E7%AB%9E%E8%B5%9B/GANLM-Encoder-Decoder-Pre-training-with-an-Auxiliary-Discriminator/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : false,
    isPost : true,
    lang   : 'zh-CN'
  };
</script>

  <title>GANLM: Encoder-Decoder Pre-training with an Auxiliary Discriminator | WarmFire</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

<link rel="alternate" href="/rss2.xml" title="WarmFire" type="application/rss+xml">
</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">WarmFire</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a>

  </li>
        <li class="menu-item menu-item-about">

    <a href="/about/" rel="section"><i class="fa fa-user fa-fw"></i>关于</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>标签</a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>分类</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档</a>

  </li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜索
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup">
        <div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off"
           placeholder="搜索..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div id="search-result">
  <div id="no-result">
    <i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>
  </div>
</div>

    </div>
  </div>

</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content post posts-expand">
            

    
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://www.warmfire.com/2023/11/27/%E7%A7%91%E7%A0%94%E7%AB%9E%E8%B5%9B/GANLM-Encoder-Decoder-Pre-training-with-an-Auxiliary-Discriminator/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.png">
      <meta itemprop="name" content="Yan Zhimin">
      <meta itemprop="description" content="不忘初心，方得始终">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="WarmFire">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          GANLM: Encoder-Decoder Pre-training with an Auxiliary Discriminator
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2023-11-27 22:58:34" itemprop="dateCreated datePublished" datetime="2023-11-27T22:58:34+08:00">2023-11-27</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2024-01-10 15:10:18" itemprop="dateModified" datetime="2024-01-10T15:10:18+08:00">2024-01-10</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E7%AB%9E%E8%B5%9B/" itemprop="url" rel="index"><span itemprop="name">竞赛</span></a>
                </span>
                  ，
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E7%AB%9E%E8%B5%9B/%E5%86%AF%E5%A6%82%E6%9D%AF%E4%B8%93%E5%88%A9/" itemprop="url" rel="index"><span itemprop="name">冯如杯专利</span></a>
                </span>
            </span>

          
            <span class="post-meta-item" title="阅读次数" id="busuanzi_container_page_pv" style="display: none;">
              <span class="post-meta-item-icon">
                <i class="fa fa-eye"></i>
              </span>
              <span class="post-meta-item-text">阅读次数：</span>
              <span id="busuanzi_value_page_pv"></span>
            </span>

          
          
        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <p>0x00 前言</p>
<p>GANLM论文翻译</p>
<span id="more"></span>
<h2><span id="abstract">Abstract</span></h2><p>Pre-trained models have achieved remarkable success in natural language processing (NLP). However, existing pre-training methods underutilize the benefits of language understanding for generation. Inspired by the idea of Generative Adversarial Networks (GANs), we propose a GAN-style model for encoder-decoder pretraining by introducing an auxiliary discriminator, unifying the ability of language under standing and generation in a single model. Our model, named as GANLM, is trained with two pre-training objectives: <strong>replaced token detection and replaced token denoising</strong>. Specifically, <strong>given masked source sentences, the generator outputs the target distribution and the discriminator predicts whether the target sampled tokens from distribution are incorrect. The target sentence is replaced with misclassified tokens to construct noisy previous context, which is used to generate the gold sentence</strong>. In general, both tasks improve the ability of language understanding and generation by selectively using the denoising data. Extensive experiments in language generation benchmarks show that GANLM with the powerful language understanding capability outperforms various strong pre-trained language models (PLMs) and achieves state-of-the-art performance.</p>
<blockquote>
<p>underutilize vt.未充分使用</p>
<p>auxiliary adj. 辅助的</p>
<p>unify v.联合</p>
<p>replace token detection 替换token检测</p>
<p>replace token denoising 替换token去噪</p>
<p>gold sentense</p>
</blockquote>
<p>预训练模型在自然语言处理(NLP)领域取得了显著的成功。然而，现有的预训练方法没有充分利用语言理解对生成的好处。受生成对抗网络(GANs)思想的启发，通过引入辅助判别器，提出了一种用于编码器-解码器预训练的gan风格的模型，将语言理解和生成的能力统一在单个模型中。该模型名为GANLM，使用两个预训练目标进行训练:<strong>替换token检测和替换token去噪</strong>。具体来说，<strong>给定掩码源句子，生成器输出目标分布，鉴别器预测来自分布的目标采样token是否不正确。将目标句子替换为错误分类的token，构建有噪声的前一个上下文，用于生成黄金句子</strong>。总的来说，这两项任务都通过有选择地使用去噪数据来提高语言理解和生成的能力。在语言生成基准上的广泛实验表明，具有强大语言理解能力的GANLM优于各种强大的预训练语言模型(plm)，并取得了最先进的性能。</p>
<h2><span id="1-introduction">1 Introduction</span></h2><p>​    The pre-training-then-fine-tuning paradigm has been proven successful in many natural language processing tasks (Devlin et al., 2019; Liu et al., 2019; Schick and Schütze, 2021). While there are various pre-training approaches for the encoder only architectures (Clark et al., 2020; Conneauet al., 2020), the encoder-decoder pre-training is underexplored, which is essential for natural language generation. To pre-train the entire encoder-decoder model, BART (Lewis et al., 2020) proposes a denoising language model objective and T5 (Raffelet al., 2020) pre-trains the models with a span corruption objective. Furthermore, mBART (Liu et al., \2020) and mT5 (Xue et al., 2021) extend them to be multilingual pre-trained language models. </p>
<p>​    预训练-然后微调的范式已被证明在许多自然语言处理任务中是成功的(Devlin等人，2019;Liu等人，2019;Schick and Schütze, 2021)。虽然有各种针对仅编码器架构的预训练方法(Clark等人，2020;Conneauet al.， 2020)，编码器-解码器预训练尚未得到充分开发，而这对自然语言生成至关重要。为了预训练整个编码器-解码器模型，BART (Lewis et al.， 2020)提出了去噪语言模型目标，T5 (Raffelet al.， 2020)预训练具有跨度破坏目标的模型。此外，mBART (Liu et al.， \2020)和mT5 (Xue et al.， 2021)将它们扩展为多语言预训练语言模型。</p>
<p>​    Unlike most encoder-decoder pre-training methods that simply apply sequence-to-sequence tasks on a single encoder-decoder architecture, we explore the approaches to pre-train the model in a GAN-style manner with an auxiliary discriminator. GAN (Goodfellow et al., 2014) performs well on both text and image generation tasks by combining the generator and discriminator. It aims to improve the ability of the generator to produce high quality samples, which is important for the encoder decoder pre-training when transferred to down stream generation tasks. Similarly, MaskGAN (Fedus et al., 2018) shows the GAN-like training can improve the quality of the autoregressive language model. Therefore, it is intuitive to leverage GAN to empower the encoder-decoder pre-training by unifying language understanding and generation. </p>
<p>​    与大多数仅在单个编码器-解码器架构上应用序列到序列任务的编码器-解码器预训练方法不同，本文探索了用辅助判别器以gan风格的方式预训练模型的方法。GAN (Goodfellow等人，2014)通过结合生成器和鉴别器，在文本和图像生成任务上表现良好。它旨在提高生成器产生高质量样本的能力，这对于将编码器-解码器预训练迁移到下游生成任务时很重要。同样，MaskGAN (Fedus et al.， 2018)表明类gan训练可以提高自回归语言模型的质量。因此，利用GAN通过统一语言理解和生成来增强编码器-解码器预训练是很直观的。</p>
<p>​    In this work, we propose a pre-training frame work GANLM, using GAN-style learning to improve the transferability of pre-trained language models for the natural language generation. Specifically, the encoder reads the masked source sentence and the generator obtains target distribution. Then, the discriminator distinguishes whether each token sampled from the target distribution matches the target gold sentence (replaced token detection). The misclassified tokens by discriminator are regarded as hard tokens for the generator to predict accurately. We replace original tokens in the target sentence with misclassified sampled ones to construct the noisy previous context for predicting the target sentence (replaced token denoising). In Figure 1,the generator predicts the masked words “guardian watered”, where the incorrect token “guardian” and correct token “watered” are both misclassified into REPLACED and ORIGINAL by the discriminator. Next, we resample a different token “watering” from the generated distribution. Consequently, the target tokens “gardener watered” are replaced with the sampled tokens “guardian watering” to construct the noisy sample. The generator predicts the next word conditioned on previous noisy tokens (replaced token denoising). Through combing two tasks, GANLM strengthen generation performance with the enhanced language understanding capability from the replaced token detection task.</p>
<p>​    本文提出一种预训练框架GANLM，用gan风格的学习来提高预训练语言模型的可迁移性，用于自然语言生成。具体来说，编码器读取被掩码的源语句，生成器获得目标分布。然后，鉴别器区分从目标分布中采样的每个token是否与目标黄金句子匹配(替换token检测)。判别器将误分类的词项视为硬词项，供生成器进行准确预测。我们将目标句子中的原始标记替换为错误分类的采样标记，以构建含噪的前一个上下文来预测目标句子(替换标记去噪)。在图1中，生成器预测了被屏蔽的单词” guardian “，其中不正确的标记” guardian “和正确的标记” “都被判别器错误地分类为替换标记和原始标记。接下来，我们从生成的分布中重新采样不同的token “浇水”。因此，将目标标记” gardener “替换为采样标记” guardian “来构建噪声样本。生成器根据之前的噪声标记(替换的标记去噪)预测下一个单词。通过将两个任务相结合，GANLM增强了生成性能，并增强了替换token检测任务的语言理解能力。</p>
<p>​    Our method is effective for text generation and can be extended to natural language understanding tasks. We pre-train GANLM model on large-scale monolingual corpora and evaluate the performance of our pre-trained English model GANLM and multilingual model GANLM-m on various downstream tasks, including text summarization, machine translation, and data-to-text generation. Experimental results demonstrate that our method substantially outperforms previous pre-trained encoder and sequence-to-sequence models on generation tasks. Our method is further tested on GLUE (Wang et al.,\2019) and XNLI (Conneau et al., 2018) to validate the transferability of our pre-trained model. Analytic experiments emphasize the importance of the discriminator in both the pre-training and finetuning stage, leading to better performance.</p>
<p>​    该方法对文本生成是有效的，可以扩展到自然语言理解任务。在大规模单语语料库上预训练了GANLM模型，并评估了预训练英语模型GANLM和多语言模型GANLM-m在各种下游任务上的性能，包括文本摘要、机器翻译和数据到文本生成。实验结果表明，该方法在生成任务上大大优于之前的预训练编码器和序列到序列模型。我们的方法在GLUE (Wang et al.，\2019)和XNLI (Conneau et al.， 2018)上进行了进一步测试，以验证预训练模型的可移植性。分析性实验强调了判别器在预训练和微调阶段的重要性，从而获得了更好的性能。</p>
<p><img src="http://warmfire-store.oss-cn-beijing.aliyuncs.com//img/image-20231127231837770.png" align="center"></p>
<p>Figure 1: A pre-training sample of our method, where replaced token detection (discriminator) and replaced token denoising (generator) are used for pre-training. The discriminator classifies each generated token into REPLACED or ORIGINAL, where REPLACED denotes the predicted token is different from the gold token. The red fonts denote incorrect predictions.</p>
<p>图1:我们方法的预训练样本，其中替换的token检测(鉴别器)和替换的token去噪(生成器)用于预训练。鉴别器将每个生成的token分类为替换的或原始的，替换表示预测的token不同于黄金token。红色字体表示错误的预测。</p>
<h2><span id="2-ganlm">2 GANLM</span></h2><h3><span id="21-model-overview">2.1 Model Overview</span></h3><p>Our GAN-style pre-trained model comprises a generator (<em>G</em>) and discriminator (<em>D</em>), which are both encoder-decoder frameworks and conditioned on the same encoder (Enc). In Figure 2, the encoder reads the masked sentence and the generator decoder obtains the target distribution. Then the discriminator decoder distinguishes whether each token in the sampled target sentence matches the gold reference. Tokens in the target gold sentence are randomly replaced with misclassified ones by the discriminator to construct the noisy sample, which is fed into the generator decoder to predict the target sentence (replaced token denoising).</p>
<p>我们的生成对抗网络（GAN）风格预训练模型包括一个生成器 (<em>G</em>) 和一个判别器 (<em>D</em>)，它们都是编码器-解码器框架，并且都在相同的编码器（Enc）的条件下。在图2中，编码器读取被掩码的句子，生成器解码器获取目标分布。然后，判别器解码器区分采样目标句子中的每个标记是否与黄金参考匹配。目标黄金句子中的标记会被判别器随机替换为被错误分类的标记，以构建含噪样本，然后将其输入生成器解码器以预测目标句子（替换标记去噪）。</p>
<h3><span id="22-masked-sequence-generator">2.2 Masked Sequence Generator</span></h3><p>Given a monolingual sentence $x = (x_1,\cdots,x_n)$ with $n$ words from the dataset $D_k$ of language $L_k \in L_{all}=\{L_1,\cdots,L_K\}(|L_{all}|=K)$, some random spans of contiguous tokens in $x$ corrupted as the source sentence, which is denoted as $x^{src}=(x_1,\cdots,x_{\backslash u:v},\cdots,x_n)$. $x_{\backslash u:v}$ is a masked span of $x_{u:v}$, where the fragment from position $u$ to $v$ is corrupted by [MASK]. Given $x^{src}$, the generator predicts the original identities of the masked tokens $x^{trg}=(x_{\backslash 1},\cdots,x_{\backslash u:v},\cdots,x_{\backslash n})$ autoregressively:</p>
<script type="math/tex; mode=display">
x^{trg}_t=Enc-Dec(x^{src},x^{trg}_{1:t-1};\{\theta_{\epsilon},\theta_{\mathcal{G}}\})</script><p>where $\theta_{\epsilon}$  and $\theta_{\mathcal{G}}$ denote the encoder and decoder parameters of the generator. Enc-Dec denotes an encoder-decoder model. The generator predicts the next position $t$ token $x^{trg}_t$ based on previous tokens. </p>
<p>给定一个单语句 $x = (x_1,\cdots,x_n)$，其中包含来自语言 $L_k$ 的数据集 $D_k$ 中的 $n$ 个单词，其中 $L_k \in L_{all}=\{L_1,\cdots,L_K\}$（$|L_{all}|=K$），$x$ 的一些连续标记的随机跨度被损坏，作为源句子表示为 $x^{src}=(x_1,\cdots,x_{\backslash u:v},\cdots,x_n)$。$x_{\backslash u:v}$ 是 $x_{u:v}$ 的一个掩码跨度，其中从位置 $u$ 到 $v$ 的片段被 [MASK] 损坏。给定 $x^{src}$，生成器通过自回归方式预测被掩码的标记的原始标识 $x^{trg}=(x_{\backslash 1},\cdots,x_{\backslash u:v},\cdots,x_{\backslash n})$：</p>
<script type="math/tex; mode=display">
x^{trg}_t=Enc-Dec(x^{src},x^{trg}_{1:t-1};\{\theta_{\epsilon},\theta_{\mathcal{G}}\}) \tag 1</script><p>其中 $\theta_{\epsilon}$ 和 $\theta_{\mathcal{G}}$ 表示生成器的编码器和解码器参数。Enc-Dec 表示一个编码器-解码器模型。生成器基于先前标记预测下一个位置 $t$ 的标记 $x^{trg}_t$。</p>
<p>​    The training objective of sequence-to-sequence masked language modeling (S2S-MLM) on the dataset $D_k$ of language $L_k$ is defined as:</p>
<script type="math/tex; mode=display">
\mathcal{L_{\mathcal{G}}}=E_{x\sim{D_k}}[\log P_G(x^{trg}|x^{src};\{\theta_{\epsilon},\theta_{\mathcal{G}}\})]</script><p>where $x^{src}$ and $x^{trg}$ are derived from $x$.</p>
<p>​    语言 $L_k$ 的序列到序列掩码语言建模（S2S-MLM）的训练目标定义为：</p>
<script type="math/tex; mode=display">
\mathcal{L_{\mathcal{G}}}=E_{x\sim{D_k}}[\log P_G(x^{trg}|x^{src};\{\theta_{\epsilon},\theta_{\mathcal{G}}\})] \tag 2</script><p>其中 $x^{src}$ 和 $x^{trg}$ 派生自 $x$。</p>
<h3><span id="23-replaced-token-detection">2.3 Replaced Token Detection</span></h3><p>The generator outputs the distribution of each target token and we create a sampled sentence $\hat{x}^{trg}$ by randomly sampling tokens from the distribution. The discriminator distinguishes whether each token in<br>$\hat{x}^{trg}$ is replaced compared to $x^{trg}$. Given the target distribution $P_G(x^{trg}_t|x^{src})(x^{trg}_t\in x^{src})$ from the generator, we construct $\hat{x}^{trg}$ for the discriminator:</p>
<script type="math/tex; mode=display">
\hat{x}^{trg} = REPLACE(x^{trg};x'_t) \\
w.r.t. x'_t \sim P_G(x^{trg}_t|x^{src})\and(x^{trg}_t\in x^{src}) \tag 3</script><blockquote>
<p>w.r.t. with respect to 关于，相对于</p>
</blockquote>
<p>生成器输出每个目标标记的分布，我们通过从分布中随机抽样标记创建一个样本句子 $\hat{x}^{trg}$。判别器区分在 $\hat{x}^{trg}$ 中的每个标记是否与 $x^{trg}$ 相比发生了替换。鉴于来自生成器的目标分布 $P_G(x^{trg}_t|x^{src})(x^{trg}_t\in x^{src})$，我们为判别器构建 $\hat{x}^{trg}$：</p>
<script type="math/tex; mode=display">
\hat{x}^{trg} = REPLACE(x^{trg};x'_t) \\
\text{w.r.t. } x'_t \sim P_G(x^{trg}_t|x^{src})\and(x^{trg}_t\in x^{src}) \tag{3}</script><p>where REPLACE($\cdot$) replaces target <em>t</em>-th position unmasked token in $x^{trg}$ with the sampled token $x’_t$<br>from the generated distribution $P_G(x^{trg}_t|x^{src})$. </p>
<p>其中，REPLACE($\cdot$) 替换 $x^{trg}$ 中目标第 <em>t</em> 位置的未掩码标记，用来自生成分布 $P_G(x^{trg}_t|x^{src})$ 的抽样标记 $x’_t$ 替换。</p>
<p>​    Given the source sentence $x^{src}$ and the encoder $\theta_{\epsilon}$ , the decoder of the discriminator $\theta_{\mathcal{D}}$ obtains a sequence of hidden representations $H_d=(h_1,\cdots,h_n)$ by feeding the sampled sentence $\hat{x}^{trg}$ to the discriminator decoder:</p>
<script type="math/tex; mode=display">
H_d =Enc-Dec(x^{src},\hat{x}^{trg};\{\theta_{\epsilon},\theta_{\mathcal{D}}\}) \tag 4</script><p>​    鉴于源句子 $x^{src}$ 和判别器的编码器 $\theta_{\epsilon}$，判别器的解码器 $\theta_{\mathcal{D}}$ 通过将抽样句子 $\hat{x}^{trg}$ 提供给判别器解码器，获得一系列隐藏表示 $H_d=(h_1,\cdots,h_n)$：</p>
<script type="math/tex; mode=display">
H_d = Enc-Dec(x^{src},\hat{x}^{trg};\{\theta_{\epsilon},\theta_{\mathcal{D}}\}) \tag{4}</script><p>where $\theta_{\epsilon}$ and $\theta_{\mathcal{D}}$ denote the encoder and decoder parameters of the discriminator. The decoder of the discriminator $\theta_{\mathcal{D}}$ adopts the bidirectional language model to classify each input token by extracting the past and future representations.</p>
<p>其中，$\theta_{\epsilon}$ 和 $\theta_{\mathcal{D}}$ 分别表示判别器的编码器和解码器参数。判别器的解码器 $\theta_{\mathcal{D}}$ 采用双向语言模型，通过提取过去和未来的表示来对每个输入标记进行分类。</p>
<p>​    Given the representations $H_d$, the discriminator classifies sampled tokens $\hat{x}^{trg}$ into the REPLACED or ORIGINAL label with a sigmoid function $\sigma$:</p>
<script type="math/tex; mode=display">
V=\sigma(H_dW_d)\tag 5</script><p>where $W_d\in R^{d_\epsilon \times 2}$ is the matrix projects the token representations to two categories (REPLACED or ORIGINAL) and $d_\epsilon$ is the model hidden size.</p>
<p>​    鉴于表示 $H_d$，判别器使用 S 型函数 $\sigma$ 将抽样标记 $\hat{x}^{trg}$ 分类为 REPLACED 或 ORIGINAL 标签：</p>
<script type="math/tex; mode=display">
V=\sigma(H_dW_d)\tag{5}</script><p>其中 $W_d\in R^{d_\epsilon \times 2}$ 是将标记表示投影到两个类别（REPLACED 或 ORIGINAL）的矩阵，$d_\epsilon$ 是模型的隐藏大小。</p>
<p>​    The training objective of the replaced token detection task for the discriminator is:</p>
<script type="math/tex; mode=display">
\mathcal{L_{\mathcal{D}}}=E_{x\sim{D_k}}[\mathbb{I}(\hat{x}^{trg}=x^{trg})\log V+\mathbb{I}(\hat{x}^{trg}\neq x^{trg})\log(1-V)] \tag 6</script><p>where $\mathbb{I}(\cdot)$ is the indicator function.</p>
<p>​    判别器替换标记检测任务的训练目标为：</p>
<script type="math/tex; mode=display">
\mathcal{L_{\mathcal{D}}}=E_{x\sim{D_k}}[\mathbb{I}(\hat{x}^{trg}=x^{trg})\log V+\mathbb{I}(\hat{x}^{trg}\neq x^{trg})\log(1-V)] \tag{6}</script><p>其中 $\mathbb{I}(\cdot)$ 是指示函数。</p>
<h3><span id="24-replaced-token-denoising">2.4 Replaced Token Denoising</span></h3><p>Although our model structure is similar to GAN,  the generator is trained with maximum likelihood rather than the standard GAN objective due to the difficulty of the GAN training in NLP. We replace tokens in $x^{trg}$ with misclassified tokens by discriminator to construct the noisy previous context $x^{trg}_f$. If the sampled token $\hat{x}^{trg}_t=x_t$  is labeled with ORIGINAL, we will resample the token $x’_t(x’_t\neq x_t)$ from target distribution as the misclassified token to modify $x_t$ in $x^{trg}$. When $\hat{x}^{trg}_t=x’_t(x’_t\neq x_t)$ is labeled with REPLACED, the miscalssified token $x’_t$ directly replaces $x_t$ in the target sentence. Given the target sentence $x^{trg}$ and generated probabilities $P_G$, we replace tokens in $x^{trg}$ with sampled tokens as the previous noisy context:</p>
<script type="math/tex; mode=display">
x^{trg}_f = REPLACE(x^{trg};\hat{x}^{trg}_t) \\
w.r.t. \ \hat{x}^{trg}_t \sim P_G(x^{trg}_t|x^{src})\and(t\in v) \tag{7}</script><p>where $v=\{v_1,\cdots,v_p\}(|v|=p)$ denotes the positions in $x^{trg}$ of the misclassified tokens. </p>
<p>尽管我们的模型结构类似于 GAN，由于在自然语言处理中 GAN 训练的困难，生成器是使用最大似然而不是标准 GAN 目标进行训练。我们通过判别器用被错误分类的标记替换 $x^{trg}$ 中的标记来构建带有噪声的先前上下文 $x^{trg}_f$。如果抽样的标记 $\hat{x}^{trg}_t=x_t$ 被标记为 ORIGINAL，我们将从目标分布中重新抽样标记 $x’_t(x’_t\neq x_t)$ 作为错误分类的标记，以修改 $x^{trg}$ 中的 $x_t$。当 $\hat{x}^{trg}_t=x’_t(x’_t\neq x_t)$ 被标记为 REPLACED 时，错误分类的标记 $x’_t$ 直接替换目标句子中的 $x_t$。给定目标句子 $x^{trg}$ 和生成的概率 $P_G$，我们用抽样的标记替换 $x^{trg}$ 中的标记，形成先前的带噪声上下文：</p>
<script type="math/tex; mode=display">
x^{trg}_f = REPLACE(x^{trg};\hat{x}^{trg}_t) \\
\text{w.r.t. } \hat{x}^{trg}_t \sim P_G(x^{trg}_t|x^{src})\text{ 且 }(t\in v) \tag{7}</script><p>其中 $v=\{v_1,\cdots,v_p\}(|v|=p)$ 表示 $x^{trg}$ 中被错误分类的标记的位置。</p>
<p>The training objective of the replaced token denoising ($\mathcal{DG}$) task based on the source sentence $x^{src}$ and target noisy context $x^{trg}_f$ is described as:</p>
<script type="math/tex; mode=display">
\mathcal{L_{\mathcal{DG}}}=E_{x\sim{D_{L_k}}}[-\log P(x^{trg}|x^{src},x^{trg}_f;\{\theta_{\epsilon},\theta_{\mathcal{D}}\})]
\tag{8}</script><p>where $x^{trg}$ is predicted by the previous noisy tokens $x^{trg}_f$ instead of previous gold context.</p>
<p>基于源句子 $x^{src}$ 和目标带噪声上下文 $x^{trg}_f$ 的替换标记去噪（$\mathcal{DG}$）任务的训练目标如下：</p>
<script type="math/tex; mode=display">
\mathcal{L_{\mathcal{DG}}}=E_{x\sim{D_{L_k}}}[-\log P(x^{trg}|x^{src},x^{trg}_f;\{\theta_{\epsilon},\theta_{\mathcal{D}}\})] \tag{8}</script><p>其中 $x^{trg}$ 是由先前的带噪声标记 $x^{trg}_f$ 预测的，而不是先前的黄金上下文。</p>
<h3><span id="25-multi-task-learning">2.5 Multi-task Learning</span></h3><p>Given multilingual corpora $D_{all}=\{D_1,\cdots,D_K\}$ of $K$ languages, the pre-trained model with parameters $\{\theta_{\epsilon},\theta_{\mathcal{G}}, \theta_{\mathcal{D}}\}$ is jointly trained over <em>K</em> languages to optimize the combined self-supervised objective as below:</p>
<script type="math/tex; mode=display">
\mathcal{L_P}=\mathbb{E}_{L_k\in L_{all}}[\mathcal{L_G}+\lambda\mathcal{L_D}+\mathcal{L_DG}] \tag{9}</script><p>where $\lambda=10.0$ is the discriminator weight and $L_{all}=\{L_1,\cdots,L_K\}$. To improve model efficiency, a tiny discriminator decoder (4 layers) is adopted to help the generator decoder (12 layers).</p>
<p>给定 $K$ 种语言的多语料库 $D_{all}=\{D_1,\cdots,D_K\}$，使用参数 $\{\theta_{\epsilon},\theta_{\mathcal{G}}, \theta_{\mathcal{D}}\}$ 的预训练模型通过在 <em>K</em> 种语言上联合训练以优化下面的综合自监督目标：</p>
<script type="math/tex; mode=display">
\mathcal{L_P}=\mathbb{E}_{L_k\in L_{all}}[\mathcal{L_G}+\lambda\mathcal{L_D}+\mathcal{L_DG}] \tag{9}</script><p>其中 $\lambda=10.0$ 是判别器权重，$L_{all}=\{L_1,\cdots,L_K\}$。为提高模型效率，使用一个较小的判别器解码器（4 层）来辅助生成器解码器（12 层）。</p>
<p><img src="http://warmfire-store.oss-cn-beijing.aliyuncs.com//img/image-20231128100203852.png" alt="image-20231128100203852"></p>
<p>Figure 2: Overview of GANLM, including (a) replaced token detection and (b) replaced token denoising. The encoder reads the source sentence and the generator obtains target distribution, where the generator and discriminator are supervised by the gold labels in (a). The discriminator distinguishes whether the sampled tokens “guardian watered” are replaced (both tokens are misclassified in this example). For the correct predicted token “watered”, we obtain a different token “watering” by resampling. The target tokens are replaced with the misclassified tokens to construct the noisy input, which are used to predict the gold sentence “gardener watered [EOS]” in (b).</p>
<p><strong>图 2：GANLM概述</strong></p>
<p><strong>(a) 替换标记检测</strong> 和 <strong>(b) 替换标记去噪</strong></p>
<p>在 (a) 中，编码器读取源句子，生成器获取目标分布，生成器和判别器在此过程中由金标签进行监督。判别器区分采样标记“guardian watered”是否被替换（在此示例中，两个标记都被错误分类）。对于正确预测的标记“watered”，我们通过重新抽样获得一个不同的标记“watering”。目标标记被替换为错误分类的标记，构建带有噪声的输入，用于预测 (b) 中的金句子“gardener watered [EOS]”。</p>
<h2><span id="3-discriminator-enhanced-fine-tuning">3 Discriminator-enhanced Fine-tuning</span></h2><p>To fully utilize the pre-trained parameters, we keep the auxiliary discriminator in downstream generation tasks (discriminator-enhanced fine-tuning) to enhance the generator, where both the pre-trained generator and discriminator are recycled. Given the annotated corpus $D_s$ of $K$ languages, the pretrained model $\{\theta_{\epsilon},\theta_{\mathcal{G}}, \theta_{\mathcal{D}}\}$ is optimized by:</p>
<script type="math/tex; mode=display">
\mathcal{L_F}=\mathbb{E}_{x,y\sim D_s}[\mathcal{L_G}+\lambda\mathcal{L_D}+\mathcal{L_DG}] \tag{10}</script><p>where $x$ and $y$ are the parallel pair from $D_s$. The objective in the fine-tuning stage use the original pair  $x$ and $y$ without S2S-MLM. The generator $\{\theta_{\epsilon},\theta_{\mathcal{G}}\}$ are kept for inference by throwing out the discriminator decoder $ \theta_{\mathcal{D}}$. Alternatively, the discriminator $(\mathcal{D}:\{\theta_{\epsilon},\theta_{\mathcal{D}}\})$ or generator $(\mathcal{G}:\{\theta_{\epsilon},\theta_{\mathcal{G}}\})$ can also be separately fine-tuned on the downstream task.</p>
<p>为了充分利用预训练参数，我们在下游生成任务中保留辅助判别器（判别器增强微调）以增强生成器，其中预训练的生成器和判别器都得到了重复利用。给定 $K$ 种语言的带标注语料库 $D_s$，预训练模型 $\{\theta_{\epsilon},\theta_{\mathcal{G}}, \theta_{\mathcal{D}}\}$ 通过以下方式进行优化：</p>
<script type="math/tex; mode=display">
\mathcal{L_F}=\mathbb{E}_{x,y\sim D_s}[\mathcal{L_G}+\lambda\mathcal{L_D}+\mathcal{L_DG}] \tag{10}</script><p>其中 $x$ 和 $y$ 是来自 $D_s$ 的平行语料对。微调阶段的目标使用原始对 $x$ 和 $y$，而不使用 S2S-MLM。生成器 $\{\theta_{\epsilon},\theta_{\mathcal{G}}\}$ 被保留用于推断，而判别器解码器 $ \theta_{\mathcal{D}}$ 被丢弃。或者，判别器 $(\mathcal{D}:\{\theta_{\epsilon},\theta_{\mathcal{D}}\})$ 或生成器 $(\mathcal{G}:\{\theta_{\epsilon},\theta_{\mathcal{G}}\})$ 也可以在下游任务上分别进行微调。</p>
<h2><span id="4-experiment-setting">4 Experiment Setting</span></h2><h3><span id="41-pre-training-details">4.1 Pre-training Details</span></h3><h4><span id="model-configuration">Model Configuration</span></h4><p>In the experiments, we adopt a sequence-to-sequence base-setting Transformer architecture with 768 hidden size, 3072 FFN (feed-forward network) dimension, 12 attention heads, and 12 encoder/decoder layers. The maximum sequence length of learned positions embeddings in the encoder/decoder is set as 1024. All token embedding matrices and output projection matrix parameters are shared for model efficiency. </p>
<h4><span id="模型配置">模型配置</span></h4><p>在实验中，我们采用了一个基于序列到序列的 Transformer 架构，具有 768 的隐藏大小，3072 的前馈网络（FFN）维度，12 个注意力头，以及 12 个编码器/解码器层。在编码器/解码器中学到的位置嵌入的最大序列长度被设置为 1024。为了提高模型效率，所有标记嵌入矩阵和输出投影矩阵参数都是共享的。</p>
<h4><span id="dataset">Dataset</span></h4><p>Following the previous work (Liu et al., 2019), our English pre-trained model GANLM is</p>
<p>trained on 160GB English monolingual data from BookCorpus, CC-News, OpenWebText, and CC Stories. In addition, we pre-train GANLM-m with 6TB multilingual data as the pioneering work (Maet al., 2021), which is a combination of CC100, CCNet, and Wikipedia, covering 100 languages. All texts are tokenized by SentencePiece (Kudo and Richardson, 2018) and encoded by the dictionary from XLM-R (Conneau et al., 2020).</p>
<h4><span id="数据集">数据集</span></h4><p>按照先前的工作（Liu et al., 2019），我们的英语预训练模型 GANLM 是在来自 BookCorpus、CC-News、OpenWebText 和 CC Stories 的 160GB 英语单语数据上训练的。此外，我们还预训了 GANLM-m，使用了 6TB 多语言数据，这是作为开创性工作（Ma et al., 2021）的一部分，涵盖了CC100、CCNet 和 Wikipedia，涵盖了 100 种语言。所有文本都由 SentencePiece（Kudo 和 Richardson, 2018）进行分词，并由 XLM-R（Conneau et al., 2020）的字典进行编码。</p>
<h4><span id="optimization">Optimization</span></h4><p>For S2S-MLM, we randomly mask 15% of the words in each instance with an average span length of 3 (Raffel et al., 2020). For the replaced token detection, we set the discriminator weight $\lambda=10.0$. We adopt Adam (Kingma and Ba, 2015) with a learning rate of 3e-4 and 10K warm-up steps for pre-training. The model is trained on 128 NVIDIA A100 GPUs (40GB) from scratch and each batch contains 8K samples. The English pre-trained model GANLM and multilingual model GANLM-m are trained for 500K steps. Specifically, all methods in Table 1 are pre-trained with 500K steps for a fair comparison.</p>
<h4><span id="优化">优化</span></h4><p>对于 S2S-MLM，我们随机地对每个实例中的 15% 单词进行屏蔽，平均跨度长度为 3（Raffel et al., 2020）。对于替换标记检测，我们设置判别器权重 $\lambda=10.0$。我们采用 Adam（Kingma 和 Ba, 2015）作为优化器，学习率为 3e-4，并进行了 10K 次热身步骤进行预训练。该模型是在 128 个 NVIDIA A100 GPU（40GB）上从头开始训练的，每个批次包含 8K 个样本。英语预训练模型 GANLM 和多语言模型 GANLM-m 训练了 500K 步。具体而言，表格1中的所有方法都进行了 500K 步的预训练，以进行公平比较。</p>
<h3><span id="42-downstream-tasks">4.2 Downstream Tasks</span></h3><h4><span id="monolingual-summarization">Monolingual Summarization</span></h4><p><strong>CNN / DailyMail</strong>(See et al., 2017) is an abstractive summarization dataset aiming at generating a concise summary from an English news article in CNN and DailyMail. As a popular abstractive summarization dataset, <strong>XSum</strong> (Narayan et al., 2018) compresses a BBC news article to a short one-sentence summary.</p>
<h4><span id="单语言摘要">单语言摘要</span></h4><p><strong>CNN/DailyMail</strong>（See et al., 2017）是一个目标生成摘要的抽象摘要数据集，旨在从 CNN 和 DailyMail 的英语新闻文章中生成简洁的摘要。作为一个受欢迎的抽象摘要数据集，<strong>XSum</strong>（Narayan et al., 2018）将 BBC 新闻文章压缩成一个简短的一句摘要。</p>
<h4><span id="multilingual-summarization">Multilingual Summarization</span></h4><p>To test the capability of our multilingual pre-trained model, a large-scale multilingual dataset named  <strong>WikiLingua</strong> (Ladhak et al., 2020) of 18 languages from WikiHow is used to evaluate multilingual abstractive summarization systems.</p>
<h4><span id="多语言摘要">多语言摘要</span></h4><p>为了测试我们多语言预训练模型的能力，我们使用了一个名为<strong>WikiLingua</strong>（Ladhak et al., 2020）的大规模多语言数据集，其中包含来自 WikiHow 的 18 种语言，用于评估多语言抽象摘要系统。</p>
<h4><span id="bilingual-translation">Bilingual Translation</span></h4><p>For the bilingual task, we use the <strong>WMT-14 English-German</strong>, <strong>WMT-14 English-French</strong>, and <strong>WMT-16 EnglishRomanian</strong> dataset for evaluation. WMT-14 En-De from WMT consists of 4.5M sentence pairs and the newstest2014 is used as the test set. WMT-14 EnFr is a large-scale dataset containing nearly 41M sentence pairs and newstest2014 is adopted for evaluation. WMT-16 En-Ro is comprised of original parallel sentences and back-translation data.</p>
<h4><span id="双语翻译">双语翻译</span></h4><p>对于双语任务，我们使用<strong>WMT-14英德</strong>、<strong>WMT-14英法</strong>和<strong>WMT-16英罗</strong>数据集进行评估。WMT-14 En-De 来自 WMT，包含 450 万个句对，newstest2014 用作测试集。WMT-14 En-Fr 是一个大规模数据集，包含近 4100 万个句对，采用 newstest2014 进行评估。WMT-16 En-Ro 由原始平行句子和反向翻译数据组成。</p>
<h4><span id="multilingual-translation">Multilingual Translation</span></h4><p><strong>IWSLT-17</strong> of 5 languages and <strong>WMT-10</strong> of 11 languages are utilized for multilingual translation. For IWSLT-17, English (En), German (De), Italian (It), Dutch (Nl), and Romanian (Ro) corpora are downloaded from the IWSLT-2017 benchmark. We use dev2010 for validation and tst2017 for test. For WMT-10, we use the parallel data of 11 languages from the WMT benchmark for evaluation (Wang et al., 2020).</p>
<h4><span id="多语言翻译">多语言翻译</span></h4><p>我们利用包含 5 种语言的<strong>IWSLT-17</strong>和包含 11 种语言的<strong>WMT-10</strong>进行多语言翻译。对于 IWSLT-17，我们从 IWSLT-2017 基准下载了英语（En）、德语（De）、意大利语（It）、荷兰语（Nl）和罗马尼亚语（Ro）语料库。我们使用 dev2010 进行验证，tst2017 进行测试。对于 WMT-10，我们使用 WMT 基准的 11 种语言的平行数据进行评估（Wang et al., 2020）。</p>
<h4><span id="data-to-text-generation">Data-to-Text Generation</span></h4><p>Data-to-text generation accepts multiple triplets and produces a description. WebNLG (Gardent et al., 2017) contains parallel DBpedia triple sets and short texts. The EnEn direction contains 17K triple sets and 45K short texts and the En-Ru direction contains 7K triple sets and 19K texts in Russian. The ROUGE scores on the valid set are reported for a fair comparison with the previous work (Gehrmann et al., 2021).</p>
<h4><span id="数据生成文本">数据生成文本</span></h4><p>数据生成文本接受多个三元组并生成描述。<strong>WebNLG</strong>（Gardent et al., 2017）包含平行的 DBpedia 三元组集和短文本。英英方向包含 17K 个三元组集和 45K 个短文本，而英俄方向包含 7K 个三元组集和 19K 个俄文文本。为了与先前的工作（Gehrmann et al., 2021）进行公平比较，报告了验证集上的 ROUGE 分数。</p>
<p><img src="http://warmfire-store.oss-cn-beijing.aliyuncs.com//img/image-20231128104227297.png" alt="image-20231128104227297"></p>
<p>Table 1: Comparison of different pre-training objectives. Particularly, all methods in this table use the base-setting model and are pre-trained with 500K steps on the same corpora for a fair comparison. We report ROUGE scores for abstractive text summarization (XSum) and BLEU scores for multilingual machine translation (IWSLT-17).</p>
<p>表1：不同预训练目标的比较。特别地，表中所有方法使用基础设置模型，并在相同的语料库上进行了50万步的预训练，以进行公平比较。我们报告了对抽象文本摘要（XSum）的ROUGE分数以及对多语言机器翻译（IWSLT-17）的BLEU分数。</p>
<p><img src="http://warmfire-store.oss-cn-beijing.aliyuncs.com//img/image-20231128104355560.png" alt="image-20231128104355560"></p>
<p>Table 2: Abstractive summarization results on the test set of CNN / DailyMail, and XSum. The evaluation metric is the F1 score of ROUGE (RG) scores.</p>
<p>表2：在CNN / DailyMail和XSum的测试集上的抽象摘要结果。评估指标是ROUGE（RG）分数的F1分数。</p>
<p><img src="http://warmfire-store.oss-cn-beijing.aliyuncs.com//img/image-20231128104426541.png" alt="image-20231128104426541"></p>
<p>Table 3: Results of our method and other baselines on multilingual abstractive summarization. We report the RG-1/RG-2/RG-L (ROUGE) F1 scores of the 18 WikiLingua languages and the average scores.</p>
<p>表3：我们的方法和其他基线在多语言抽象摘要上的结果。我们报告了对18种WikiLingua语言的ROUGE-1/ROUGE-2/ROUGE-L（ROUGE）F1分数以及平均分数。</p>
<h3><span id="43-fine-tuning-details">4.3 Fine-tuning Details</span></h3><h4><span id="abstractive-summarization">Abstractive Summarization</span></h4><p>During fine-tuning, we use the Adam (Kingma and Ba, 2015) optimizer with an initial learning rate of 1e-4 and the batch size is set as 2048 tokens on 8 V100 GPUs. The models are trained with the label smoothing cross entropy with a smoothing ratio of 0.1.</p>
<h4><span id="抽象摘要">抽象摘要</span></h4><p>在微调过程中，我们使用Adam优化器（Kingma和Ba，2015），初始学习率为1e-4，批大小设置为在8个V100 GPU上为2048个标记。模型使用标签平滑的交叉熵进行训练，平滑比例为0.1。</p>
<h4><span id="neural-machine-translation">Neural Machine Translation</span></h4><p>For the large-scale multilingual dataset WMT-10, our pre-trained model is fine-tuned on 32 V100 GPUs with a learning rate of 3e-4. For all bilingual translation tasks and the IWSLT-2017 benchmark, we adopt Adam with a learning rate of 1e-4 and set the batch size as 2048 tokens on 8 V100 GPUs.</p>
<h4><span id="神经机器翻译">神经机器翻译</span></h4><p>对于大规模多语言数据集WMT-10，我们的预训练模型在32个V100 GPU上进行微调，学习率为3e-4。对于所有的双语翻译任务和IWSLT-2017基准测试，我们采用Adam优化器，学习率为1e-4，并在8个V100 GPU上将批大小设置为2048个标记。</p>
<h4><span id="data-to-text-generation">Data-to-text Generation</span></h4><p>We use Adam with a learning rate of {8e-5,1e-4} and set the batch size as 16 sentences on the WebNLG dataset.</p>
<h4><span id="数据到文本生成">数据到文本生成</span></h4><p>在WebNLG数据集上，我们使用Adam优化器，学习率为{8e-5, 1e-4}，批大小设置为16个句子。</p>
<h2><span id="5-comparing-pre-training-objectives">5 Comparing Pre-training Objectives</span></h2><p>To verify the potential of our pre-training task under a fair comparison, we re-implement previous pre-training tasks and pre-trains baselines on the same corpora with 500K steps, including BERT/mBERT (Devlin et al., 2019), ELECTRA (Clark et al., 2020), BART (Lewis et al., 2020)/mBART (Liu et al., 2020), and T5 (Raffel et al.,2020)/mT5 (Xue et al., 2021). Table 1 reports the ROUGE and BLEU points on the summarization dataset XSum and multilingual translation dataset IWSLT-17. All models have 12 encoder and 12 decoder layers with a hidden size of 768. We observe that the encoder-decoder pre-trained model (T5/mT5) outperforms the pre-trained encoder (ELECTRA, BERT/mBERT), which corroborates the encoder-decoder pre-training is morebeneficial to the downstream generation task. Experiments ⑥<em>∼</em>⑧ show the importance of the discriminator and replaced token denoising. Experiment ⑧ demonstrates that only the replaced token detection task can still bring improvement through strengthening the encoder shared by both generator and discriminator. Besides, the replaced token detection task is also helpful to downstream language understanding tasks with a powerful encoder. Lastly, the results verify that fine-tuning with the help of the pre-trained auxiliary discriminator further improves performance.</p>
<p>为了在公平比较下验证我们预训练任务的潜力，我们重新实现了以前的预训练任务，并在相同的语料库上进行了500K步的预训练，包括BERT/mBERT（Devlin等人，2019）、ELECTRA（Clark等人，2020）、BART（Lewis等人，2020）/mBART（Liu等人，2020）和T5（Raffel等人，2020）/mT5（Xue等人，2021）。表1报告了在摘要数据集XSum和多语言翻译数据集IWSLT-17上的ROUGE和BLEU分数。所有模型都有12个编码器层和12个解码器层，隐藏大小为768。我们观察到编码器-解码器预训练模型（T5/mT5）优于仅进行编码器预训练的模型（ELECTRA、BERT/mBERT），这证实了编码器-解码器预训练对下游生成任务更有益。实验⑥<em>∼</em>⑧展示了鉴别器和替换标记去噪的重要性。实验⑧表明，仅替换标记检测任务仍然可以通过强化生成器和鉴别器共享的编码器来带来改善。此外，替换标记检测任务对具有强大编码器的下游语言理解任务也有帮助。最后，结果验证了在辅助预训练鉴别器的帮助下进行微调能够进一步提高性能。</p>
<h2><span id="6-results-of-ganlm">6 Results of GANLM</span></h2><p>The English pre-trained model GANLM is evaluated on the abstractive text summarization task with the ROUGE (Lin, 2004) scores.</p>
<p>英文预训练模型 GANLM 在抽象文本摘要任务上通过 ROUGE（Lin, 2004）分数进行评估。</p>
<h3><span id="xsum">XSum</span></h3><p>As shown in Table 2, the pre-training methods achieve significant improvements over the strong baseline PTRNET without pre-training. The sequence-to-sequence pre-trained model such as UniLMv2 + <em>s2s-ft</em> outperforms other pre-training baselines, where the pseudo-masked technique is applied to the fine-tuning stage. Our method beats all pre-training baselines by a large margin with the discriminator-enhanced fine-tuning strategy. It emphasizes the importance of the fine-tuning strategy for the performance of downstream tasks.</p>
<p>如表2所示，预训练方法在没有预训练的强基准模型 PTRNET 上取得了显著的改进。诸如 UniLMv2 + <em>s2s-ft</em> 这样的序列到序列预训练模型在精调阶段应用了伪掩码技术，优于其他预训练基准。我们的方法通过鉴别器增强的微调策略在所有预训练基准上大幅领先。这强调了微调策略对下游任务性能的重要性。</p>
<h3><span id="cnn-dailymail">CNN / DailyMail</span></h3><p>Our method is also evaluated on the CNN / DailyMail dataset in Table 2. The comparisons further indicate that our method obtains strong performance on generation by leveraging the discriminator.</p>
<p>我们的方法还在CNN / DailyMail数据集上进行了评估，如表2所示。进一步的比较表明，我们的方法通过利用鉴别器在生成任务上取得了强大的性能。</p>
<h2><span id="7-results-of-ganlm-m">7 Results of GANLM-m</span></h2><p>To evaluate the multilingual pre-trained model GANLM-m, we report the BLEU (Papineni et al., \2002) scores for machine translation and ROUGE (Lin, 2004) scores for text summarization and data to-text generation.</p>
<p>为了评估多语言预训练模型 GANLM-m，我们报告了机器翻译的 BLEU（Papineni等人，2002）分数，以及文本摘要和数据到文本生成的 ROUGE（Lin, 2004）分数。</p>
<h3><span id="wikilingua">WikiLingua</span></h3><p>Table 3 reports the average ROUGE scores of 18 WikiLingua languages. The large improvement over other pre-training method demon strate the summarization ability of our GANLM-m.</p>
<p>表3报告了18种 WikiLingua 语言的平均 ROUGE 分数。与其他预训练方法相比的巨大改进表明了我们的 GANLM-m 的摘要能力。</p>
<h3><span id="wmt14-en-de">WMT14 En-De</span></h3><p>The results on the bilingual translation are presented at Table 4. We observe that the proposed GANLM outperforms all previous works in the high-resource machine translation scenario (<em>&gt;</em> 4M sentence pairs).</p>
<p>双语翻译的结果显示在表4中。我们观察到，在高资源机器翻译场景（*&gt; 4M 句对）中，我们提出的 GANLM 胜过了所有先前的工作。</p>
<h3><span id="wmt14-en-fr">WMT14 En-Fr</span></h3><p>We further conduct experiments on the WMT14 En-Fr bilingual translation task. Table 4 GANLM-m shows that GANLM-m still brings significant improvement to the downstream task with large-scale machine translation fine tuning data (<em>&gt;</em> 40M sentence pairs).</p>
<p>我们在WMT14 En-Fr双语翻译任务上进一步进行实验。表4中的 GANLM-m 显示，GANLM-m 仍然在大规模机器翻译微调数据（*&gt; 40M 句对）上为下游任务带来显著的改进。</p>
<h3><span id="wmt16-en-ro">WMT16 En-Ro</span></h3><p>For the low-resource setting (&lt;1M sentence pairs), there is an average gain of +4 BLEU points compared to the Transformer baseline in Table 5. With the same back-translation data, GANLM-m further improves the model performance and still beats other baselines.</p>
<p>在低资源设置（&lt;1M 句对）中，与表5中的 Transformer 基线相比，平均 BLEU 分数提高了 +4 分。在相同的回译数据情况下，GANLM-m 进一步提高了模型性能，并仍然击败了其他基线。</p>
<h3><span id="wmt-10">WMT-10</span></h3><p>For the multilingual translation, we compare GANLM-m with the strong multilingual pre-trained models in Table 7 and Table 6, such as mBART (Liu et al., 2020). It is notable our method outperforms large pre-trained model mBART with 1024 hidden size by a large margin (+1<em>∼</em>2 BLEU points). Plus, there is a +1.5 BLEU gain over XLMR, whose encoder and decoder are initialized by the cross-lingual pre-trained encoder (Ma et al., 2020).</p>
<p>对于多语言翻译，我们在表7和表6中与强大的多语言预训练模型进行比较，如 mBART（Liu等人，2020）。值得注意的是，我们的方法在 BLEU 分数上大幅胜过具有 1024 隐藏大小的大型预训练模型 mBART（+1<em>∼</em>2 BLEU 分数）。此外，与由跨语言预训练编码器初始化的 XLM-R 相比，还有 +1.5 BLEU 的提升。</p>
<h3><span id="webnlg">WebNLG</span></h3><p>Table 8 presents the performance on the data-to-text generation task, showing that GANLM outperforms multilingual sequence-to sequence pre-training baselines mBART and mT5 by +2 ROUGE-L points on both languages.</p>
<p>表8展示了在数据到文本生成任务上的性能，表明 GANLM 在两种语言上都在 ROUGE-L 分数上优于多语言序列到序列预训练基线 mBART 和 mT5（+2 ROUGE-L 分数）。</p>
<p><img src="http://warmfire-store.oss-cn-beijing.aliyuncs.com//img/image-20231128105705309.png" alt="image-20231128105705309"></p>
<p>Table 4: Comparison with other pre-training approaches on the WMT14 En-De and WMT14 En-Fr benchmark.</p>
<p>表4：在WMT14 En-De和WMT14 En-Fr基准上与其他预训练方法的比较。</p>
<p><img src="http://warmfire-store.oss-cn-beijing.aliyuncs.com//img/image-20231128105718279.png" alt="image-20231128105718279"></p>
<p>Table 5: Comparison with other pre-training methods on the WMT16 En-Ro benchmark.<br>表5：在WMT16 En-Ro基准上与其他预训练方法的比较。</p>
<h2><span id="8-analysis">8 Analysis</span></h2><p><hr><br>版权信息</p>

    </div>

    
    
    
        <div class="reward-container">
  <div></div>
  <button onclick="var qr = document.getElementById('qr'); qr.style.display = (qr.style.display === 'none') ? 'block' : 'none';">
    打赏
  </button>
  <div id="qr" style="display: none;">
      
      <div style="display: inline-block;">
        <img src="/images/wechatpay.jpg" alt="Yan Zhimin 微信支付">
        <p>微信支付</p>
      </div>

  </div>
</div>

        

<div>
<ul class="post-copyright">
  <li class="post-copyright-author">
    <strong>本文作者： </strong>Yan Zhimin
  </li>
  <li class="post-copyright-link">
    <strong>本文链接：</strong>
    <a href="http://www.warmfire.com/2023/11/27/%E7%A7%91%E7%A0%94%E7%AB%9E%E8%B5%9B/GANLM-Encoder-Decoder-Pre-training-with-an-Auxiliary-Discriminator/" title="GANLM: Encoder-Decoder Pre-training with an Auxiliary Discriminator">http://www.warmfire.com/2023/11/27/科研竞赛/GANLM-Encoder-Decoder-Pre-training-with-an-Auxiliary-Discriminator/</a>
  </li>
  <li class="post-copyright-license">
    <strong>版权声明： </strong>本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" rel="noopener" target="_blank"><i class="fab fa-fw fa-creative-commons"></i>BY-NC-SA</a> 许可协议。转载请注明出处！
  </li>
</ul>
</div>


      <footer class="post-footer">
          <div class="post-tags">
              <a href="/tags/%E7%A7%91%E7%A0%94%E7%AB%9E%E8%B5%9B/" rel="tag"># 科研竞赛</a>
          </div>

        


        
    <div class="post-nav">
      <div class="post-nav-item">
    <a href="/2023/11/27/%E7%A7%91%E7%A0%94%E7%AB%9E%E8%B5%9B/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/" rel="prev" title="机器学习学习记录">
      <i class="fa fa-chevron-left"></i> 机器学习学习记录
    </a></div>
      <div class="post-nav-item">
    <a href="/2023/12/06/%E5%AD%A6%E6%A0%A1%E8%AF%BE%E7%A8%8B/%E5%B7%A5%E7%A7%91%E6%95%B0%E5%AD%A6%E5%88%86%E6%9E%90/%E6%95%B0%E5%88%86%E7%AC%AC14%E5%91%A8%E5%AD%A6%E4%B9%A0%E6%97%A5%E5%BF%97/" rel="next" title="数分第14周学习日志">
      数分第14周学习日志 <i class="fa fa-chevron-right"></i>
    </a></div>
    </div>
      </footer>
    
  </article>
  
  
  

  
  <div>
    <div>
    
        <div style="text-align:center;color: #ccc;font-size:24px;">-------------本文结束<i class="fa fa-paw"></i>感谢您的阅读-------------</div>
    
</div>
  </div>
 



          </div>
          
    
  <div class="comments">
    <div id="lv-container" data-id="city" data-uid="MTAyMC81OTAxMy8zNTQ3NQ=="></div>
  </div>
  

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link"><span class="nav-number">1.</span> <span class="nav-text">Abstract</span></a></li><li class="nav-item nav-level-2"><a class="nav-link"><span class="nav-number">2.</span> <span class="nav-text">1 Introduction</span></a></li><li class="nav-item nav-level-2"><a class="nav-link"><span class="nav-number">3.</span> <span class="nav-text">2 GANLM</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link"><span class="nav-number">3.1.</span> <span class="nav-text">2.1 Model Overview</span></a></li><li class="nav-item nav-level-3"><a class="nav-link"><span class="nav-number">3.2.</span> <span class="nav-text">2.2 Masked Sequence Generator</span></a></li><li class="nav-item nav-level-3"><a class="nav-link"><span class="nav-number">3.3.</span> <span class="nav-text">2.3 Replaced Token Detection</span></a></li><li class="nav-item nav-level-3"><a class="nav-link"><span class="nav-number">3.4.</span> <span class="nav-text">2.4 Replaced Token Denoising</span></a></li><li class="nav-item nav-level-3"><a class="nav-link"><span class="nav-number">3.5.</span> <span class="nav-text">2.5 Multi-task Learning</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link"><span class="nav-number">4.</span> <span class="nav-text">3 Discriminator-enhanced Fine-tuning</span></a></li><li class="nav-item nav-level-2"><a class="nav-link"><span class="nav-number">5.</span> <span class="nav-text">4 Experiment Setting</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link"><span class="nav-number">5.1.</span> <span class="nav-text">4.1 Pre-training Details</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link"><span class="nav-number">5.1.1.</span> <span class="nav-text">Model Configuration</span></a></li><li class="nav-item nav-level-4"><a class="nav-link"><span class="nav-number">5.1.2.</span> <span class="nav-text">模型配置</span></a></li><li class="nav-item nav-level-4"><a class="nav-link"><span class="nav-number">5.1.3.</span> <span class="nav-text">Dataset</span></a></li><li class="nav-item nav-level-4"><a class="nav-link"><span class="nav-number">5.1.4.</span> <span class="nav-text">数据集</span></a></li><li class="nav-item nav-level-4"><a class="nav-link"><span class="nav-number">5.1.5.</span> <span class="nav-text">Optimization</span></a></li><li class="nav-item nav-level-4"><a class="nav-link"><span class="nav-number">5.1.6.</span> <span class="nav-text">优化</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link"><span class="nav-number">5.2.</span> <span class="nav-text">4.2 Downstream Tasks</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link"><span class="nav-number">5.2.1.</span> <span class="nav-text">Monolingual Summarization</span></a></li><li class="nav-item nav-level-4"><a class="nav-link"><span class="nav-number">5.2.2.</span> <span class="nav-text">单语言摘要</span></a></li><li class="nav-item nav-level-4"><a class="nav-link"><span class="nav-number">5.2.3.</span> <span class="nav-text">Multilingual Summarization</span></a></li><li class="nav-item nav-level-4"><a class="nav-link"><span class="nav-number">5.2.4.</span> <span class="nav-text">多语言摘要</span></a></li><li class="nav-item nav-level-4"><a class="nav-link"><span class="nav-number">5.2.5.</span> <span class="nav-text">Bilingual Translation</span></a></li><li class="nav-item nav-level-4"><a class="nav-link"><span class="nav-number">5.2.6.</span> <span class="nav-text">双语翻译</span></a></li><li class="nav-item nav-level-4"><a class="nav-link"><span class="nav-number">5.2.7.</span> <span class="nav-text">Multilingual Translation</span></a></li><li class="nav-item nav-level-4"><a class="nav-link"><span class="nav-number">5.2.8.</span> <span class="nav-text">多语言翻译</span></a></li><li class="nav-item nav-level-4"><a class="nav-link"><span class="nav-number">5.2.9.</span> <span class="nav-text">Data-to-Text Generation</span></a></li><li class="nav-item nav-level-4"><a class="nav-link"><span class="nav-number">5.2.10.</span> <span class="nav-text">数据生成文本</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link"><span class="nav-number">5.3.</span> <span class="nav-text">4.3 Fine-tuning Details</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link"><span class="nav-number">5.3.1.</span> <span class="nav-text">Abstractive Summarization</span></a></li><li class="nav-item nav-level-4"><a class="nav-link"><span class="nav-number">5.3.2.</span> <span class="nav-text">抽象摘要</span></a></li><li class="nav-item nav-level-4"><a class="nav-link"><span class="nav-number">5.3.3.</span> <span class="nav-text">Neural Machine Translation</span></a></li><li class="nav-item nav-level-4"><a class="nav-link"><span class="nav-number">5.3.4.</span> <span class="nav-text">神经机器翻译</span></a></li><li class="nav-item nav-level-4"><a class="nav-link"><span class="nav-number">5.3.5.</span> <span class="nav-text">Data-to-text Generation</span></a></li><li class="nav-item nav-level-4"><a class="nav-link"><span class="nav-number">5.3.6.</span> <span class="nav-text">数据到文本生成</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link"><span class="nav-number">6.</span> <span class="nav-text">5 Comparing Pre-training Objectives</span></a></li><li class="nav-item nav-level-2"><a class="nav-link"><span class="nav-number">7.</span> <span class="nav-text">6 Results of GANLM</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link"><span class="nav-number">7.1.</span> <span class="nav-text">XSum</span></a></li><li class="nav-item nav-level-3"><a class="nav-link"><span class="nav-number">7.2.</span> <span class="nav-text">CNN &#x2F; DailyMail</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link"><span class="nav-number">8.</span> <span class="nav-text">7 Results of GANLM-m</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link"><span class="nav-number">8.1.</span> <span class="nav-text">WikiLingua</span></a></li><li class="nav-item nav-level-3"><a class="nav-link"><span class="nav-number">8.2.</span> <span class="nav-text">WMT14 En-De</span></a></li><li class="nav-item nav-level-3"><a class="nav-link"><span class="nav-number">8.3.</span> <span class="nav-text">WMT14 En-Fr</span></a></li><li class="nav-item nav-level-3"><a class="nav-link"><span class="nav-number">8.4.</span> <span class="nav-text">WMT16 En-Ro</span></a></li><li class="nav-item nav-level-3"><a class="nav-link"><span class="nav-number">8.5.</span> <span class="nav-text">WMT-10</span></a></li><li class="nav-item nav-level-3"><a class="nav-link"><span class="nav-number">8.6.</span> <span class="nav-text">WebNLG</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link"><span class="nav-number">9.</span> <span class="nav-text">8 Analysis</span></a></li></ol></div>
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="Yan Zhimin"
      src="/images/avatar.png">
  <p class="site-author-name" itemprop="name">Yan Zhimin</p>
  <div class="site-description" itemprop="description">不忘初心，方得始终</div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">64</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">18</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">6</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 2023-09 – 
  <span itemprop="copyrightYear">2024</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Yan Zhimin</span>
</div>
  <div class="powered-by">由 <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://muse.theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Muse</a> 强力驱动
  </div>


    <script async src="//dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js"></script>

    <span id="busuanzi_container_site_pv">总访问量<span id="busuanzi_value_site_pv"></span>次</span>
    <span class="post-meta-divider">|</span>
    <span id="busuanzi_container_site_uv">总访客数<span id="busuanzi_value_site_uv"></span>人</span>
    <span class="post-meta-divider">|</span>
<!-- 不蒜子计数初始值纠正 -->
<script>
$(document).ready(function() {

    var int = setInterval(fixCount, 50);  // 50ms周期检测函数
    var countOffset = 20000;  // 初始化首次数据

    function fixCount() {            
       if (document.getElementById("busuanzi_container_site_pv").style.display != "none")
        {
            $("#busuanzi_value_site_pv").html(parseInt($("#busuanzi_value_site_pv").html()) + countOffset); 
            clearInterval(int);
        }                  
        if ($("#busuanzi_container_site_pv").css("display") != "none")
        {
            $("#busuanzi_value_site_uv").html(parseInt($("#busuanzi_value_site_uv").html()) + countOffset); // 加上初始数据 
            clearInterval(int); // 停止检测
        }  
    }
       	
});
</script> 

        
<div class="busuanzi-count">
  <script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
    <span class="post-meta-item" id="busuanzi_container_site_uv" style="display: none;">
      <span class="post-meta-item-icon">
        <i class="fa fa-user"></i>
      </span>
      <span class="site-uv" title="总访客量">
        <span id="busuanzi_value_site_uv"></span>
      </span>
    </span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item" id="busuanzi_container_site_pv" style="display: none;">
      <span class="post-meta-item-icon">
        <i class="fa fa-eye"></i>
      </span>
      <span class="site-pv" title="总访问量">
        <span id="busuanzi_value_site_pv"></span>
      </span>
    </span>
</div>








      </div>
    </footer>
  </div>

  
  
  <script color='0,0,255' opacity='0.5' zIndex='-1' count='99' src="/lib/canvas-nest/canvas-nest.min.js"></script>
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/muse.js"></script>


<script src="/js/next-boot.js"></script>


  <script defer src="/lib/three/three.min.js"></script>


  




  
<script src="/js/local-search.js"></script>













  

  
      

<script>
  if (typeof MathJax === 'undefined') {
    window.MathJax = {
      loader: {
        source: {
          '[tex]/amsCd': '[tex]/amscd',
          '[tex]/AMScd': '[tex]/amscd'
        }
      },
      tex: {
        inlineMath: {'[+]': [['$', '$']]},
        tags: 'ams'
      },
      options: {
        renderActions: {
          findScript: [10, doc => {
            document.querySelectorAll('script[type^="math/tex"]').forEach(node => {
              const display = !!node.type.match(/; *mode=display/);
              const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display);
              const text = document.createTextNode('');
              node.parentNode.replaceChild(text, node);
              math.start = {node: text, delim: '', n: 0};
              math.end = {node: text, delim: '', n: 0};
              doc.math.push(math);
            });
          }, '', false],
          insertedScript: [200, () => {
            document.querySelectorAll('mjx-container').forEach(node => {
              let target = node.parentNode;
              if (target.nodeName.toLowerCase() === 'li') {
                target.parentNode.classList.add('has-jax');
              }
            });
          }, '', false]
        }
      }
    };
    (function () {
      var script = document.createElement('script');
      script.src = '//cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js';
      script.defer = true;
      document.head.appendChild(script);
    })();
  } else {
    MathJax.startup.document.state(0);
    MathJax.texReset();
    MathJax.typeset();
  }
</script>

    

  

<script>
NexT.utils.loadComments(document.querySelector('#lv-container'), () => {
  window.livereOptions = {
    refer: location.pathname.replace(CONFIG.root, '').replace('index.html', '')
  };
  (function(d, s) {
    var j, e = d.getElementsByTagName(s)[0];
    if (typeof LivereTower === 'function') { return; }
    j = d.createElement(s);
    j.src = 'https://cdn-city.livere.com/js/embed.dist.js';
    j.async = true;
    e.parentNode.insertBefore(j, e);
  })(document, 'script');
});
</script>

<script async>window.onload=function(){var a=document.createElement('script'),b=document.getElementsByTagName('script')[0];a.type='text/javascript',a.async=!0,a.src='/sw-register.js?v='+Date.now(),b.parentNode.insertBefore(a,b)};</script></body></html>